rtabmap_odom:
  ros__parameters:
    frame_id: "base_link"  # Robot's body frame
    odom_frame_id: "odom"  # Output odometry frame
    subscribe_stereo: True
    approx_sync: True
    approx_sync_max_interval: 0.01
    queue_size: 3

    Reg/Force3DoF: "true"

    Rtabmap/LoggerLeve: "3"

    # Odometry tuning
    Vis/MinInliers: "20"
    Odom/Strategy: "1"
    Odom/MaxGuessDistance: "0.3"
    StereoEgoMotion/MaxTranslation: "0.3"
    Vis/CorType: "1"

    Odom/FilteringStrategy: "0"
    Odom/FilterSmoothFactor: "0.1"  # Higher trust in predicted motion
    # Odom/GuessMotion: "true"        # Predict motion from past velocity

    publish_tf: false
    publish_null_when_lost: true

    # # Optional but useful for tuning
    # stereo_from_depth: false
    # stereo_fx: 0.0  # Overwritten by camera_info
    # stereo_baseline: 0.0  # Overwritten by camera_info

    # Filtering / Motion model
    # wait_for_transform: false
    wait_imu_to_init: false  # set to true if using IMU initialization

    OdomF2M/MaxSize: "1000"
    Odom/MaxFeatures: "600"
    Odom/MinInliers: "20"
    Odom/FeatureType: "ORB"  # Try SURF or SIFT if CPU permits
    Odom/ResetCountdown: "1"




# aden-mckinney@pierre:~/Desktop/classes/sd/Navigation_Assisted_Shopping_Cart/navis_ros2_ws$ ros2 run rtabmap_odom stereo_odometry --params
# Param: BRIEF/Bytes = "32"                                  [Bytes is a length of descriptor in bytes. It can be equal 16, 32 or 64 bytes.]
# Param: BRISK/Octaves = "3"                                 [Detection octaves. Use 0 to do single scale.]
# Param: BRISK/PatternScale = "1"                            [Apply this scale to the pattern used for sampling the neighbourhood of a keypoint.]
# Param: BRISK/Thresh = "30"                                 [FAST/AGAST detection threshold score.]
# Param: FAST/CV = "0"                                       [Enable FastCV implementation if non-zero (and RTAB-Map is built with FastCV support). Values should be 9 and 10.]
# Param: FAST/Gpu = "false"                                  [GPU-FAST: Use GPU version of FAST. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
# Param: FAST/GpuKeypointsRatio = "0.05"                     [Used with FAST GPU.]
# Param: FAST/GridCols = "0"                                 [Grid cols (0 to disable). Adapts the detector to partition the source image into a grid and detect points in each cell.]
# Param: FAST/GridRows = "0"                                 [Grid rows (0 to disable). Adapts the detector to partition the source image into a grid and detect points in each cell.]
# Param: FAST/MaxThreshold = "200"                           [Maximum threshold. Used only when FAST/GridRows and FAST/GridCols are set.]
# Param: FAST/MinThreshold = "7"                             [Minimum threshold. Used only when FAST/GridRows and FAST/GridCols are set.]
# Param: FAST/NonmaxSuppression = "true"                     [If true, non-maximum suppression is applied to detected corners (keypoints).]
# Param: FAST/Threshold = "20"                               [Threshold on difference between intensity of the central pixel and pixels of a circle around this pixel.]
# Param: FREAK/NOctaves = "4"                                [Number of octaves covered by the detected keypoints.]
# Param: FREAK/OrientationNormalized = "true"                [Enable orientation normalization.]
# Param: FREAK/PatternScale = "22"                           [Scaling of the description pattern.]
# Param: FREAK/ScaleNormalized = "true"                      [Enable scale normalization.]
# Param: GFTT/BlockSize = "3"                                []
# Param: GFTT/Gpu = "false"                                  [GPU-GFTT: Use GPU version of GFTT. This option is enabled only if OpenCV>=3 is built with CUDA and GPUs are detected.]
# Param: GFTT/K = "0.04"                                     []
# Param: GFTT/MinDistance = "7"                              []
# Param: GFTT/QualityLevel = "0.001"                         []
# Param: GFTT/UseHarrisDetector = "false"                    []
# Param: GMS/ThresholdFactor = "6.0"                         [The higher, the less matches.]
# Param: GMS/WithRotation = "false"                          [Take rotation transformation into account.]
# Param: GMS/WithScale = "false"                             [Take scale transformation into account.]
# Param: GTSAM/IncRelinearizeSkip = "1"                      [Only relinearize any variables every X calls to ISAM2::update(). See GTSAM::ISAM2 doc for more info.]
# Param: GTSAM/IncRelinearizeThreshold = "0.01"              [Only relinearize variables whose linear delta magnitude is greater than this threshold. See GTSAM::ISAM2 doc for more info.]
# Param: GTSAM/Incremental = "false"                         [Do graph optimization incrementally (iSAM2) to increase optimization speed on loop closures. Note that only GaussNewton and Dogleg optimization algorithms are supported (GTSAM/Optimizer) in this mode.]
# Param: GTSAM/Optimizer = "1"                               [0=Levenberg 1=GaussNewton 2=Dogleg]
# Param: KAZE/Diffusivity = "1"                              [Diffusivity type: 0=DIFF_PM_G1, 1=DIFF_PM_G2, 2=DIFF_WEICKERT or 3=DIFF_CHARBONNIER.]
# Param: KAZE/Extended = "false"                             [Set to enable extraction of extended (128-byte) descriptor.]
# Param: KAZE/NOctaveLayers = "4"                            [Default number of sublevels per scale level.]
# Param: KAZE/NOctaves = "4"                                 [Maximum octave evolution of the image.]
# Param: KAZE/Threshold = "0.001"                            [Detector response threshold to accept keypoint.]
# Param: KAZE/Upright = "false"                              [Set to enable use of upright descriptors (non rotation-invariant).]
# Param: Kp/ByteToFloat = "false"                            [For Kp/NNStrategy=1, binary descriptors are converted to float by converting each byte to float instead of converting each bit to float. When converting bytes instead of bits, less memory is used and search is faster at the cost of slightly less accurate matching.]
# Param: ORB/EdgeThreshold = "19"                            [This is size of the border where the features are not detected. It should roughly match the patchSize parameter.]
# Param: ORB/FirstLevel = "0"                                [It should be 0 in the current implementation.]
# Param: ORB/Gpu = "false"                                   [GPU-ORB: Use GPU version of ORB. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
# Param: ORB/NLevels = "3"                                   [The number of pyramid levels. The smallest level will have linear size equal to input_image_linear_size/pow(scaleFactor, nlevels).]
# Param: ORB/PatchSize = "31"                                [size of the patch used by the oriented BRIEF descriptor. Of course, on smaller pyramid layers the perceived image area covered by a feature will be larger.]
# Param: ORB/ScaleFactor = "2"                               [Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor will mean that to cover certain scale range you will need more pyramid levels and so the speed will suffer.]
# Param: ORB/ScoreType = "0"                                 [The default HARRIS_SCORE=0 means that Harris algorithm is used to rank features (the score is written to KeyPoint::score and is used to retain best nfeatures features); FAST_SCORE=1 is alternative value of the parameter that produces slightly less stable keypoints, but it is a little faster to compute.]
# Param: ORB/WTA_K = "2"                                     [The number of points that produce each element of the oriented BRIEF descriptor. The default value 2 means the BRIEF where we take a random point pair and compare their brightnesses, so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3 random points (of course, those point coordinates are random, but they are generated from the pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such output will occupy 2 bits, and therefore it will need a special variant of Hamming distance, denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).]
# Param: Odom/AlignWithGround = "false"                      [Align odometry with the ground on initialization.]
# Param: Odom/Deskewing = "true"                             [Lidar deskewing. If input lidar has time channel, it will be deskewed with a constant motion model (with IMU orientation and/or guess if provided).]
# Param: Odom/FillInfoData = "true"                          [Fill info with data (inliers/outliers features).]
# Param: Odom/FilteringStrategy = "0"                        [0=No filtering 1=Kalman filtering 2=Particle filtering. This filter is used to smooth the odometry output.]
# Param: Odom/GuessMotion = "true"                           [Guess next transformation from the last motion computed.]
# Param: Odom/GuessSmoothingDelay = "0"                      [Guess smoothing delay (s). Estimated velocity is averaged based on last transforms up to this maximum delay. This can help to get smoother velocity prediction. Last velocity computed is used directly if "Odom/FilteringStrategy" is set or the delay is below the odometry rate.]
# Param: Odom/Holonomic = "true"                             [If the robot is holonomic (strafing commands can be issued). If not, y value will be estimated from x and yaw values (y=x*tan(yaw)).]
# Param: Odom/ImageBufferSize = "1"                          [Data buffer size (0 min inf).]
# Param: Odom/ImageDecimation = "1"                          [Decimation of the RGB image before registration. If depth size is larger than decimated RGB size, depth is decimated to be always at most equal to RGB size. If Vis/DepthAsMask is true and if depth is smaller than decimated RGB, depth may be interpolated to match RGB size for feature detection.]
# Param: Odom/KalmanMeasurementNoise = "0.01"                [Process measurement covariance value.]
# Param: Odom/KalmanProcessNoise = "0.001"                   [Process noise covariance value.]
# Param: Odom/KeyFrameThr = "0.3"                            [[Visual] Create a new keyframe when the number of inliers drops under this ratio of features in last frame. Setting the value to 0 means that a keyframe is created for each processed frame.]
# Param: Odom/ParticleLambdaR = "100"                        [Lambda of rotational components (roll,pitch,yaw).]
# Param: Odom/ParticleLambdaT = "100"                        [Lambda of translation components (x,y,z).]
# Param: Odom/ParticleNoiseR = "0.002"                       [Noise (rad) of rotational components (roll,pitch,yaw).]
# Param: Odom/ParticleNoiseT = "0.002"                       [Noise (m) of translation components (x,y,z).]
# Param: Odom/ParticleSize = "400"                           [Number of particles of the filter.]
# Param: Odom/ResetCountdown = "0"                           [Automatically reset odometry after X consecutive images on which odometry cannot be computed (value=0 disables auto-reset).]
# Param: Odom/ScanKeyFrameThr = "0.9"                        [[Geometry] Create a new keyframe when the number of ICP inliers drops under this ratio of points in last frame's scan. Setting the value to 0 means that a keyframe is created for each processed frame.]
# Param: Odom/Strategy = "0"                                 [0=Frame-to-Map (F2M) 1=Frame-to-Frame (F2F) 2=Fovis 3=viso2 4=DVO-SLAM 5=ORB_SLAM2 6=OKVIS 7=LOAM 8=MSCKF_VIO 9=VINS-Fusion 10=OpenVINS 11=FLOAM 12=Open3D]
# Param: Odom/VisKeyFrameThr = "150"                         [[Visual] Create a new keyframe when the number of inliers drops under this threshold. Setting the value to 0 means that a keyframe is created for each processed frame.]
# Param: OdomF2M/BundleAdjustment = "1"                      [Local bundle adjustment: 0=disabled, 1=g2o, 2=cvsba, 3=Ceres.]
# Param: OdomF2M/BundleAdjustmentMaxFrames = "10"            [Maximum frames used for bundle adjustment (0=inf or all current frames in the local map).]
# Param: OdomF2M/BundleAdjustmentMaxKeyFramesPerFeature = "0" [Maximum keyframes per feature for bundle adjustment. 0 means not limit.]
# Param: OdomF2M/BundleAdjustmentMinMotion = "0.0"           [To create a new keyframe with bundle adjustment, a minimum motion (in pixels) can be required. The motion is computed by the average distance between inliers of the previous keyframe and new frame.]
# Param: OdomF2M/BundleUpdateFeatureMapOnAllFrames = "false" [Update 3D local feature map on every frame with bundle adjustment. Recommended if Vis/DepthAsMask=false and Mem/UseOdomFeatures=true so that features without depth are better triangulated on every frame (not only on keyframes). If disabled, the feature map is updated only when a new keyframe is added (legacy approach).]
# Param: OdomF2M/FloorThreshold = "0.0"                      [[Visual] Only track features in 3D feature map that are over this threshold (height in base frame). Can be useful to ignore reflections on the floor. 0 means disabled.]
# Param: OdomF2M/InitDepthFactor = "0.05"                    [[Visual] Depth factor used to initialize depth of features without depth. Depth = Factor * fx.]
# Param: OdomF2M/MaxNewFeatures = "0"                        [[Visual] Maximum features (sorted by keypoint response) added to local map from a new key-frame. 0 means no limit.]
# Param: OdomF2M/MaxSize = "2000"                            [[Visual] Local map size: If > 0 (example 5000), the odometry will maintain a local map of X maximum words.]
# Param: OdomF2M/ScanMaxSize = "2000"                        [[Geometry] Maximum local scan map size.]
# Param: OdomF2M/ScanRange = "0"                             [[Geometry] Distance Range used to filter points of local map (when > 0). 0 means local map is updated using time and not range.]
# Param: OdomF2M/ScanSubtractAngle = "45"                    [[Geometry] Max angle (degrees) used to filter points of a new added scan to local map (when "OdomF2M/ScanSubtractRadius">0). 0 means any angle.]
# Param: OdomF2M/ScanSubtractRadius = "0.05"                 [[Geometry] Radius used to filter points of a new added scan to local map. This could match the voxel size of the scans.]
# Param: OdomF2M/ValidDepthRatio = "0.75"                    [If a new frame has points without valid depth, they are added to local feature map only if points with valid depth on total points is over this ratio. Setting to 1 means no points without valid depth are added to local feature map.]
# Param: OdomFovis/BucketHeight = "80"                       []
# Param: OdomFovis/BucketWidth = "80"                        []
# Param: OdomFovis/CliqueInlierThreshold = "0.1"             [See Howard's greedy max-clique algorithm for determining the maximum set of mutually consisten feature matches. This specifies the compatibility threshold, in meters.]
# Param: OdomFovis/FastThreshold = "20"                      [FAST threshold.]
# Param: OdomFovis/FastThresholdAdaptiveGain = "0.005"       [FAST threshold adaptive gain.]
# Param: OdomFovis/FeatureSearchWindow = "25"                [Specifies the size of the search window to apply when searching for feature matches across time frames.  The search is conducted around the feature location predicted by the initial rotation estimate.]
# Param: OdomFovis/FeatureWindowSize = "9"                   [The size of the n x n image patch surrounding each feature, used for keypoint matching.]
# Param: OdomFovis/InlierMaxReprojectionError = "1.5"        [The maximum image-space reprojection error (in pixels) a feature match is allowed to have and still be considered an inlier in the set of features used for motion estimation.]
# Param: OdomFovis/MaxKeypointsPerBucket = "25"              []
# Param: OdomFovis/MaxMeanReprojectionError = "10.0"         [Maximum mean reprojection error over the inlier feature matches for the motion estimate to be considered valid.]
# Param: OdomFovis/MaxPyramidLevel = "3"                     [The maximum Gaussian pyramid level to process the image at. Pyramid level 1 corresponds to the original image.]
# Param: OdomFovis/MinFeaturesForEstimate = "20"             [Minimum number of features in the inlier set for the motion estimate to be considered valid.]
# Param: OdomFovis/MinPyramidLevel = "0"                     [The minimum pyramid level.]
# Param: OdomFovis/StereoMaxDisparity = "128"                []
# Param: OdomFovis/StereoMaxDistEpipolarLine = "1.5"         []
# Param: OdomFovis/StereoMaxRefinementDisplacement = "1.0"   []
# Param: OdomFovis/StereoRequireMutualMatch = "true"         []
# Param: OdomFovis/TargetPixelsPerFeature = "250"            [Specifies the desired feature density as a ratio of input image pixels per feature detected.  This number is used to control the adaptive feature thresholding.]
# Param: OdomFovis/UpdateTargetFeaturesWithRefined = "false" [When subpixel refinement is enabled, the refined feature locations can be saved over the original feature locations.  This has a slightly negative impact on frame-to-frame visual odometry, but is likely better when using this library as part of a visual SLAM algorithm.]
# Param: OdomFovis/UseAdaptiveThreshold = "true"             [Use FAST adaptive threshold.]
# Param: OdomFovis/UseBucketing = "true"                     []
# Param: OdomFovis/UseHomographyInitialization = "true"      [Use homography initialization.]
# Param: OdomFovis/UseImageNormalization = "false"           []
# Param: OdomFovis/UseSubpixelRefinement = "true"            [Specifies whether or not to refine feature matches to subpixel resolution.]
# Param: OdomLOAM/AngVar = "0.01"                            [Angular output variance.]
# Param: OdomLOAM/LinVar = "0.01"                            [Linear output variance.]
# Param: OdomLOAM/LocalMapping = "true"                      [Local mapping. It adds more time to compute odometry, but accuracy is significantly improved.]
# Param: OdomLOAM/Resolution = "0.2"                         [Map resolution]
# Param: OdomLOAM/ScanPeriod = "0.1"                         [Scan period (s)]
# Param: OdomLOAM/Sensor = "2"                               [Velodyne sensor: 0=VLP-16, 1=HDL-32, 2=HDL-64E]
# Param: OdomMSCKF/FastThreshold = "10"                      []
# Param: OdomMSCKF/GridCol = "5"                             []
# Param: OdomMSCKF/GridMaxFeatureNum = "4"                   []
# Param: OdomMSCKF/GridMinFeatureNum = "3"                   []
# Param: OdomMSCKF/GridRow = "4"                             []
# Param: OdomMSCKF/InitCovAccBias = "0.01"                   []
# Param: OdomMSCKF/InitCovExRot = "0.00030462"               []
# Param: OdomMSCKF/InitCovExTrans = "0.000025"               []
# Param: OdomMSCKF/InitCovGyroBias = "0.01"                  []
# Param: OdomMSCKF/InitCovVel = "0.25"                       []
# Param: OdomMSCKF/MaxCamStateSize = "20"                    []
# Param: OdomMSCKF/MaxIteration = "30"                       []
# Param: OdomMSCKF/NoiseAcc = "0.05"                         []
# Param: OdomMSCKF/NoiseAccBias = "0.01"                     []
# Param: OdomMSCKF/NoiseFeature = "0.035"                    []
# Param: OdomMSCKF/NoiseGyro = "0.005"                       []
# Param: OdomMSCKF/NoiseGyroBias = "0.001"                   []
# Param: OdomMSCKF/OptTranslationThreshold = "0"             []
# Param: OdomMSCKF/PatchSize = "15"                          []
# Param: OdomMSCKF/PositionStdThreshold = "8.0"              []
# Param: OdomMSCKF/PyramidLevels = "3"                       []
# Param: OdomMSCKF/RansacThreshold = "3"                     []
# Param: OdomMSCKF/RotationThreshold = "0.2618"              []
# Param: OdomMSCKF/StereoThreshold = "5"                     []
# Param: OdomMSCKF/TrackPrecision = "0.01"                   []
# Param: OdomMSCKF/TrackingRateThreshold = "0.5"             []
# Param: OdomMSCKF/TranslationThreshold = "0.4"              []
# Param: OdomMono/InitMinFlow = "100"                        [Minimum optical flow required for the initialization step.]
# Param: OdomMono/InitMinTranslation = "0.1"                 [Minimum translation required for the initialization step.]
# Param: OdomMono/MaxVariance = "0.01"                       [Maximum variance to add new points to local map.]
# Param: OdomMono/MinTranslation = "0.02"                    [Minimum translation to add new points to local map. On initialization, translation x 5 is used as the minimum.]
# Param: OdomOKVIS/ConfigPath = ""                           [Path of OKVIS config file.]
# Param: OdomORBSLAM/AccNoise = "0.1"                        [IMU accelerometer "white noise".]
# Param: OdomORBSLAM/AccWalk = "0.0001"                      [IMU accelerometer "random walk".]
# Param: OdomORBSLAM/Bf = "0.076"                            [Fake IR projector baseline (m) used only when stereo is not used.]
# Param: OdomORBSLAM/Fps = "0.0"                             [Camera FPS (0 to estimate from input data).]
# Param: OdomORBSLAM/GyroNoise = "0.01"                      [IMU gyroscope "white noise".]
# Param: OdomORBSLAM/GyroWalk = "0.000001"                   [IMU gyroscope "random walk".]
# Param: OdomORBSLAM/Inertial = "false"                      [Enable IMU. Only supported with ORB_SLAM3.]
# Param: OdomORBSLAM/MapSize = "3000"                        [Maximum size of the feature map (0 means infinite). Only supported with ORB_SLAM2.]
# Param: OdomORBSLAM/MaxFeatures = "1000"                    [Maximum ORB features extracted per frame.]
# Param: OdomORBSLAM/SamplingRate = "0"                      [IMU sampling rate (0 to estimate from input data).]
# Param: OdomORBSLAM/ThDepth = "40.0"                        [Close/Far threshold. Baseline times.]
# Param: OdomORBSLAM/VocPath = ""                            [Path to ORB vocabulary (*.txt).]
# Param: OdomOpen3D/MaxDepth = "3.0"                         [Maximum depth.]
# Param: OdomOpen3D/Method = "0"                             [Registration method: 0=PointToPlane, 1=Intensity, 2=Hybrid.]
# Param: OdomOpenVINS/AccelerometerNoiseDensity = "0.01"     [[m/s^2/sqrt(Hz)] (accel "white noise")]
# Param: OdomOpenVINS/AccelerometerRandomWalk = "0.001"      [[m/s^3/sqrt(Hz)] (accel bias diffusion)]
# Param: OdomOpenVINS/CalibCamExtrinsics = "false"           [Bool to determine whether or not to calibrate imu-to-camera pose]
# Param: OdomOpenVINS/CalibCamIntrinsics = "false"           [Bool to determine whether or not to calibrate camera intrinsics]
# Param: OdomOpenVINS/CalibCamTimeoffset = "false"           [Bool to determine whether or not to calibrate camera to IMU time offset]
# Param: OdomOpenVINS/CalibIMUGSensitivity = "false"         [Bool to determine whether or not to calibrate the Gravity sensitivity]
# Param: OdomOpenVINS/CalibIMUIntrinsics = "false"           [Bool to determine whether or not to calibrate the IMU intrinsics]
# Param: OdomOpenVINS/DtSLAMDelay = "0.0"                    [Delay, in seconds, that we should wait from init before we start estimating SLAM features]
# Param: OdomOpenVINS/FeatRepMSCKF = "0"                     [What representation our features are in (msckf features)]
# Param: OdomOpenVINS/FeatRepSLAM = "4"                      [What representation our features are in (slam features)]
# Param: OdomOpenVINS/FiMaxBaseline = "40"                   [Max baseline ratio to accept triangulated features]
# Param: OdomOpenVINS/FiMaxCondNumber = "10000"              [Max condition number of linear triangulation matrix accept triangulated features]
# Param: OdomOpenVINS/FiMaxRuns = "5"                        [Max runs for Levenberg-Marquardt]
# Param: OdomOpenVINS/FiRefineFeatures = "true"              [If we should perform Levenberg-Marquardt refinement]
# Param: OdomOpenVINS/FiTriangulate1d = "false"              [If we should perform 1d triangulation instead of 3d]
# Param: OdomOpenVINS/GravityMag = "9.81"                    [Gravity magnitude in the global frame (i.e. should be 9.81 typically)]
# Param: OdomOpenVINS/GyroscopeNoiseDensity = "0.001"        [[rad/s/sqrt(Hz)] (gyro "white noise")]
# Param: OdomOpenVINS/GyroscopeRandomWalk = "0.0001"         [[rad/s^2/sqrt(Hz)] (gyro bias diffusion)]
# Param: OdomOpenVINS/InitDynInflationBa = "100.0"           [What to inflate the recovered bias_a covariance by]
# Param: OdomOpenVINS/InitDynInflationBg = "10.0"            [What to inflate the recovered bias_g covariance by]
# Param: OdomOpenVINS/InitDynInflationOri = "10.0"           [What to inflate the recovered q_GtoI covariance by]
# Param: OdomOpenVINS/InitDynInflationVel = "100.0"          [What to inflate the recovered v_IinG covariance by]
# Param: OdomOpenVINS/InitDynMLEMaxIter = "50"               [How many iterations the MLE refinement should use (zero to skip the MLE)]
# Param: OdomOpenVINS/InitDynMLEMaxThreads = "6"             [How many threads the MLE should use]
# Param: OdomOpenVINS/InitDynMLEMaxTime = "0.05"             [How many seconds the MLE should be completed in]
# Param: OdomOpenVINS/InitDynMLEOptCalib = "false"           [If we should optimize calibration during intialization (not recommended)]
# Param: OdomOpenVINS/InitDynMinDeg = "10.0"                 [Orientation change needed to try to init]
# Param: OdomOpenVINS/InitDynMinRecCond = "1e-15"            [Reciprocal condition number thresh for info inversion]
# Param: OdomOpenVINS/InitDynNumPose = "6"                   [Number of poses to use within our window time (evenly spaced)]
# Param: OdomOpenVINS/InitDynUse = "false"                   [If dynamic initialization should be used]
# Param: OdomOpenVINS/InitIMUThresh = "1.0"                  [Variance threshold on our acceleration to be classified as moving]
# Param: OdomOpenVINS/InitMaxDisparity = "10.0"              [Max disparity to consider the platform stationary (dependent on resolution)]
# Param: OdomOpenVINS/InitMaxFeatures = "50"                 [How many features to track during initialization (saves on computation)]
# Param: OdomOpenVINS/InitWindowTime = "2.0"                 [Amount of time we will initialize over (seconds)]
# Param: OdomOpenVINS/Integration = "1"                      [0=discrete, 1=rk4, 2=analytical (if rk4 or analytical used then analytical covariance propagation is used)]
# Param: OdomOpenVINS/LeftMaskPath = ""                      [Mask for left image]
# Param: OdomOpenVINS/MaxClones = "11"                       [Max clone size of sliding window]
# Param: OdomOpenVINS/MaxMSCKFInUpdate = "50"                [Max number of MSCKF features we will use at a given image timestep.]
# Param: OdomOpenVINS/MaxSLAM = "50"                         [Max number of estimated SLAM features]
# Param: OdomOpenVINS/MaxSLAMInUpdate = "25"                 [Max number of SLAM features we allow to be included in a single EKF update.]
# Param: OdomOpenVINS/MinPxDist = "15"                       [Eistance between features (features near each other provide less information)]
# Param: OdomOpenVINS/NumPts = "200"                         [Number of points (per camera) we will extract and try to track]
# Param: OdomOpenVINS/RightMaskPath = ""                     [Mask for right image]
# Param: OdomOpenVINS/TryZUPT = "true"                       [If we should try to use zero velocity update]
# Param: OdomOpenVINS/UpMSCKFChi2Multiplier = "1.0"          [Chi2 multiplier for MSCKF features]
# Param: OdomOpenVINS/UpMSCKFSigmaPx = "1.0"                 [Pixel noise for MSCKF features]
# Param: OdomOpenVINS/UpSLAMChi2Multiplier = "1.0"           [Chi2 multiplier for SLAM features]
# Param: OdomOpenVINS/UpSLAMSigmaPx = "1.0"                  [Pixel noise for SLAM features]
# Param: OdomOpenVINS/UseFEJ = "true"                        [If first-estimate Jacobians should be used (enable for good consistency)]
# Param: OdomOpenVINS/UseKLT = "true"                        [If true we will use KLT, otherwise use a ORB descriptor + robust matching]
# Param: OdomOpenVINS/UseStereo = "true"                     [If we have more than 1 camera, if we should try to track stereo constraints between pairs]
# Param: OdomOpenVINS/ZUPTChi2Multiplier = "0.0"             [Chi2 multiplier for zero velocity]
# Param: OdomOpenVINS/ZUPTMaxDisparity = "0.5"               [Max disparity we will consider to try to do a zupt (i.e. if above this, don't do zupt)]
# Param: OdomOpenVINS/ZUPTMaxVelodicy = "0.1"                [Max velocity we will consider to try to do a zupt (i.e. if above this, don't do zupt)]
# Param: OdomOpenVINS/ZUPTNoiseMultiplier = "10.0"           [Multiplier of our zupt measurement IMU noise matrix (default should be 1.0)]
# Param: OdomOpenVINS/ZUPTOnlyAtBeginning = "false"          [If we should only use the zupt at the very beginning static initialization phase]
# Param: OdomVINS/ConfigPath = ""                            [Path of VINS config file.]
# Param: OdomViso2/BucketHeight = "50"                       [Height of bucket.]
# Param: OdomViso2/BucketMaxFeatures = "2"                   [Maximal number of features per bucket.]
# Param: OdomViso2/BucketWidth = "50"                        [Width of bucket.]
# Param: OdomViso2/InlierThreshold = "2.0"                   [Fundamental matrix inlier threshold.]
# Param: OdomViso2/MatchBinsize = "50"                       [Matching bin width/height (affects efficiency only).]
# Param: OdomViso2/MatchDispTolerance = "2"                  [Disparity tolerance for stereo matches (in pixels).]
# Param: OdomViso2/MatchHalfResolution = "true"              [Match at half resolution, refine at full resolution.]
# Param: OdomViso2/MatchMultiStage = "true"                  [Multistage matching (denser and faster).]
# Param: OdomViso2/MatchNmsN = "3"                           [Non-max-suppression: min. distance between maxima (in pixels).]
# Param: OdomViso2/MatchNmsTau = "50"                        [Non-max-suppression: interest point peakiness threshold.]
# Param: OdomViso2/MatchOutlierDispTolerance = "5"           [Outlier removal: disparity tolerance (in pixels).]
# Param: OdomViso2/MatchOutlierFlowTolerance = "5"           [Outlier removal: flow tolerance (in pixels).]
# Param: OdomViso2/MatchRadius = "200"                       [Matching radius (du/dv in pixels).]
# Param: OdomViso2/MatchRefinement = "1"                     [Refinement (0=none,1=pixel,2=subpixel).]
# Param: OdomViso2/RansacIters = "200"                       [Number of RANSAC iterations.]
# Param: OdomViso2/Reweighting = "true"                      [Lower border weights (more robust to calibration errors).]
# Param: Optimizer/Epsilon = "0.00001"                       [Stop optimizing when the error improvement is less than this value.]
# Param: Optimizer/GravitySigma = "0.3"                      [Gravity sigma value (>=0, typically between 0.1 and 0.3). Optimization is done while preserving gravity orientation of the poses. This should be used only with visual/lidar inertial odometry approaches, for which we assume that all odometry poses are aligned with gravity. Set to 0 to disable gravity constraints. Currently supported only with g2o and GTSAM optimization strategies (see Optimizer/Strategy).]
# Param: Optimizer/Iterations = "20"                         [Optimization iterations.]
# Param: Optimizer/LandmarksIgnored = "false"                [Ignore landmark constraints while optimizing. Currently only g2o and gtsam optimization supports this.]
# Param: Optimizer/PriorsIgnored = "true"                    [Ignore prior constraints (global pose or GPS) while optimizing. Currently only g2o and gtsam optimization supports this.]
# Param: Optimizer/Robust = "false"                          [Robust graph optimization using Vertigo (only work for g2o and GTSAM optimization strategies). Not compatible with "RGBD/OptimizeMaxError" if enabled.]
# Param: Optimizer/Strategy = "2"                            [Graph optimization strategy: 0=TORO, 1=g2o, 2=GTSAM and 3=Ceres.]
# Param: Optimizer/VarianceIgnored = "false"                 [Ignore constraints' variance. If checked, identity information matrix is used for each constraint. Otherwise, an information matrix is generated from the variance saved in the links.]
# Param: PyDetector/Cuda = "true"                            [Use cuda.]
# Param: PyDetector/Path = ""                                [Path to python script file (see available ones in rtabmap/corelib/src/python/*). See the header to see where the script should be copied.]
# Param: PyMatcher/Cuda = "true"                             [Used by SuperGlue.]
# Param: PyMatcher/Iterations = "20"                         [Sinkhorn iterations. Used by SuperGlue.]
# Param: PyMatcher/Model = "indoor"                          [For SuperGlue, set only "indoor" or "outdoor". For OANet, set path to one of the pth file (e.g., "OANet/model/gl3d/sift-4000/model_best.pth").]
# Param: PyMatcher/Path = ""                                 [Path to python script file (see available ones in rtabmap/corelib/src/python/*). See the header to see where the script should be copied.]
# Param: PyMatcher/Threshold = "0.2"                         [Used by SuperGlue.]
# Param: Reg/Force3DoF = "false"                             [Force 3 degrees-of-freedom transform (3Dof: x,y and yaw). Parameters z, roll and pitch will be set to 0.]
# Param: Reg/RepeatOnce = "true"                             [Do a second registration with the output of the first registration as guess. Only done if no guess was provided for the first registration (like on loop closure). It can be useful if the registration approach used can use a guess to get better matches.]
# Param: Reg/Strategy = "0"                                  [0=Vis, 1=Icp, 2=VisIcp]
# Param: Rtabmap/ImagesAlreadyRectified = "true"             [Images are already rectified. By default RTAB-Map assumes that received images are rectified. If they are not, they can be rectified by RTAB-Map if this parameter is false.]
# Param: Rtabmap/PublishRAMUsage = "false"                   [Publishing RAM usage in statistics (may add a small overhead to get info from the system).]
# Param: SIFT/ContrastThreshold = "0.04"                     [The contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector. Not used by CudaSift (see SIFT/GaussianThreshold instead).]
# Param: SIFT/EdgeThreshold = "10"                           [The threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are filtered out (more features are retained).]
# Param: SIFT/GaussianThreshold = "2.0"                      [CudaSift: Threshold on difference of Gaussians for feature pruning. The higher the threshold, the less features are produced by the detector.]
# Param: SIFT/Gpu = "false"                                  [CudaSift: Use GPU version of SIFT. This option is enabled only if RTAB-Map is built with CudaSift dependency and GPUs are detected.]
# Param: SIFT/NOctaveLayers = "3"                            [The number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution. Not used by CudaSift, the number of octaves is still computed automatically.]
# Param: SIFT/PreciseUpscale = "false"                       [Whether to enable precise upscaling in the scale pyramid (OpenCV >= 4.8).]
# Param: SIFT/RootSIFT = "false"                             [Apply RootSIFT normalization of the descriptors.]
# Param: SIFT/Sigma = "1.6"                                  [The sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.]
# Param: SIFT/Upscale = "false"                              [CudaSift: Whether to enable upscaling.]
# Param: SURF/Extended = "false"                             [Extended descriptor flag (true - use extended 128-element descriptors; false - use 64-element descriptors).]
# Param: SURF/GpuKeypointsRatio = "0.01"                     [Used with SURF GPU.]
# Param: SURF/GpuVersion = "false"                           [GPU-SURF: Use GPU version of SURF. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
# Param: SURF/HessianThreshold = "500"                       [Threshold for hessian keypoint detector used in SURF.]
# Param: SURF/OctaveLayers = "2"                             [Number of octave layers within each octave.]
# Param: SURF/Octaves = "4"                                  [Number of pyramid octaves the keypoint detector will use.]
# Param: SURF/Upright = "false"                              [Up-right or rotated features flag (true - do not compute orientation of features; false - compute orientation).]
# Param: Stereo/DenseStrategy = "0"                          [0=cv::StereoBM, 1=cv::StereoSGBM]
# Param: Stereo/Eps = "0.01"                                 [[Stereo/OpticalFlow=true] Epsilon stop criterion.]
# Param: Stereo/Gpu = "false"                                [[Stereo/OpticalFlow=true] Enable GPU version of the optical flow approach (only available if OpenCV is built with CUDA).]
# Param: Stereo/Iterations = "30"                            [Maximum iterations.]
# Param: Stereo/MaxDisparity = "128.0"                       [Maximum disparity.]
# Param: Stereo/MaxLevel = "5"                               [Maximum pyramid level.]
# Param: Stereo/MinDisparity = "0.5"                         [Minimum disparity.]
# Param: Stereo/OpticalFlow = "true"                         [Use optical flow to find stereo correspondences, otherwise a simple block matching approach is used.]
# Param: Stereo/SSD = "true"                                 [[Stereo/OpticalFlow=false] Use Sum of Squared Differences (SSD) window, otherwise Sum of Absolute Differences (SAD) window is used.]
# Param: Stereo/WinHeight = "3"                              [Window height.]
# Param: Stereo/WinWidth = "15"                              [Window width.]
# Param: SuperPoint/Cuda = "true"                            [Use Cuda device for Torch, otherwise CPU device is used by default.]
# Param: SuperPoint/ModelPath = ""                           [[Required] Path to pre-trained weights Torch file of SuperPoint (*.pt).]
# Param: SuperPoint/NMS = "true"                             [If true, non-maximum suppression is applied to detected keypoints.]
# Param: SuperPoint/NMSRadius = "4"                          [[SuperPoint/NMS=true] Minimum distance (pixels) between keypoints.]
# Param: SuperPoint/Threshold = "0.010"                      [Detector response threshold to accept keypoint.]
# Param: Vis/BundleAdjustment = "1"                          [Optimization with bundle adjustment: 0=disabled, 1=g2o, 2=cvsba, 3=Ceres.]
# Param: Vis/CorFlowEps = "0.01"                             [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
# Param: Vis/CorFlowGpu = "false"                            [[Vis/CorType=1] Enable GPU version of the optical flow approach (only available if OpenCV is built with CUDA).]
# Param: Vis/CorFlowIterations = "30"                        [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
# Param: Vis/CorFlowMaxLevel = "3"                           [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
# Param: Vis/CorFlowWinSize = "16"                           [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
# Param: Vis/CorGuessMatchToProjection = "false"             [[Vis/CorType=0] Match frame's corners to source's projected points (when guess transform is provided) instead of projected points to frame's corners.]
# Param: Vis/CorGuessWinSize = "40"                          [[Vis/CorType=0] Matching window size (pixels) around projected points when a guess transform is provided to find correspondences. 0 means disabled.]
# Param: Vis/CorNNDR = "0.8"                                 [[Vis/CorType=0] NNDR: nearest neighbor distance ratio. Used for knn features matching approach.]
# Param: Vis/CorNNType = "1"                                 [[Vis/CorType=0] kNNFlannNaive=0, kNNFlannKdTree=1, kNNFlannLSH=2, kNNBruteForce=3, kNNBruteForceGPU=4, BruteForceCrossCheck=5, SuperGlue=6, GMS=7. Used for features matching approach.]
# Param: Vis/CorType = "0"                                   [Correspondences computation approach: 0=Features Matching, 1=Optical Flow]
# Param: Vis/DepthAsMask = "true"                            [Use depth image as mask when extracting features.]
# Param: Vis/DepthMaskFloorThr = "0.0"                       [Filter floor from depth mask below specified threshold (m) before extracting features. 0 means disabled, negative means remove all objects above the floor threshold instead. Ignored if Vis/DepthAsMask is false.]
# Param: Vis/EpipolarGeometryVar = "0.1"                     [[Vis/EstimationType = 2] Epipolar geometry maximum variance to accept the transformation.]
# Param: Vis/EstimationType = "1"                            [Motion estimation approach: 0:3D->3D, 1:3D->2D (PnP), 2:2D->2D (Epipolar Geometry)]
# Param: Vis/FeatureType = "8"                               [0=SURF 1=SIFT 2=ORB 3=FAST/FREAK 4=FAST/BRIEF 5=GFTT/FREAK 6=GFTT/BRIEF 7=BRISK 8=GFTT/ORB 9=KAZE 10=ORB-OCTREE 11=SuperPoint 12=SURF/FREAK 13=GFTT/DAISY 14=SURF/DAISY 15=PyDetector]
# Param: Vis/GridCols = "1"                                  [Number of columns of the grid used to extract uniformly "Vis/MaxFeatures / grid cells" features from each cell.]
# Param: Vis/GridRows = "1"                                  [Number of rows of the grid used to extract uniformly "Vis/MaxFeatures / grid cells" features from each cell.]
# Param: Vis/InlierDistance = "0.1"                          [[Vis/EstimationType = 0] Maximum distance for feature correspondences. Used by 3D->3D estimation approach.]
# Param: Vis/Iterations = "300"                              [Maximum iterations to compute the transform.]
# Param: Vis/MaxDepth = "0"                                  [Max depth of the features (0 means no limit).]
# Param: Vis/MaxFeatures = "1000"                            [0 no limits.]
# Param: Vis/MeanInliersDistance = "0.0"                     [Maximum distance (m) of the mean distance of inliers from the camera to accept the transformation. 0 means disabled.]
# Param: Vis/MinDepth = "0"                                  [Min depth of the features (0 means no limit).]
# Param: Vis/MinInliers = "20"                               [Minimum feature correspondences to compute/accept the transformation.]
# Param: Vis/MinInliersDistribution = "0.0"                  [Minimum distribution value of the inliers in the image to accept the transformation. The distribution is the second eigen value of the PCA (Principal Component Analysis) on the keypoints of the normalized image [-0.5, 0.5]. The value would be between 0 and 0.5. 0 means disabled.]
# Param: Vis/PnPFlags = "0"                                  [[Vis/EstimationType = 1] PnP flags: 0=Iterative, 1=EPNP, 2=P3P]
# Param: Vis/PnPMaxVariance = "0.0"                          [[Vis/EstimationType = 1] Max linear variance between 3D point correspondences after PnP. 0 means disabled.]
# Param: Vis/PnPRefineIterations = "0"                       [[Vis/EstimationType = 1] Refine iterations. Set to 0 if "Vis/BundleAdjustment" is also used.]
# Param: Vis/PnPReprojError = "2"                            [[Vis/EstimationType = 1] PnP reprojection error.]
# Param: Vis/PnPSamplingPolicy = "1"                         [[Vis/EstimationType = 1] Multi-camera random sampling policy: 0=AUTO, 1=ANY, 2=HOMOGENEOUS. With HOMOGENEOUS policy, RANSAC will be done uniformly against all cameras, so at least 2 matches per camera are required. With ANY policy, RANSAC is not constraint to sample on all cameras at the same time. AUTO policy will use HOMOGENEOUS if there are at least 2 matches per camera, otherwise it will fallback to ANY policy.]
# Param: Vis/PnPSplitLinearCovComponents = "false"           [[Vis/EstimationType = 1] Compute variance for each linear component instead of using the combined XYZ variance for all linear components.]
# Param: Vis/PnPVarianceMedianRatio = "4"                    [[Vis/EstimationType = 1] Ratio used to compute variance of the estimated transformation if 3D correspondences are provided (should be > 1). The higher it is, the smaller the covariance will be. With accurate depth estimation, this could be set to 2. For depth estimated by stereo, 4 or more maybe used to ignore large errors of very far points.]
# Param: Vis/RefineIterations = "5"                          [[Vis/EstimationType = 0] Number of iterations used to refine the transformation found by RANSAC. 0 means that the transformation is not refined.]
# Param: Vis/RoiRatios = "0.0 0.0 0.0 0.0"                   [Region of interest ratios [left, right, top, bottom].]
# Param: Vis/SSC = "false"                                   [If true, SSC (Suppression via Square Covering) is applied to limit keypoints.]
# Param: Vis/SubPixEps = "0.02"                              [See cv::cornerSubPix().]
# Param: Vis/SubPixIterations = "0"                          [See cv::cornerSubPix(). 0 disables sub pixel refining.]
# Param: Vis/SubPixWinSize = "3"                             [See cv::cornerSubPix().]
# Param: g2o/Baseline = "0.075"                              [When doing bundle adjustment with RGB-D data, we can set a fake baseline (m) to do stereo bundle adjustment (if 0, mono bundle adjustment is done). For stereo data, the baseline in the calibration is used directly.]
# Param: g2o/Optimizer = "0"                                 [0=Levenberg 1=GaussNewton]
# Param: g2o/PixelVariance = "1.0"                           [Pixel variance used for bundle adjustment.]
# Param: g2o/RobustKernelDelta = "8"                         [Robust kernel delta used for bundle adjustment (0 means don't use robust kernel). Observations with chi2 over this threshold will be ignored in the second optimization pass.]
# Param: g2o/Solver = "0"                                    [0=csparse 1=pcg 2=cholmod 3=Eigen]